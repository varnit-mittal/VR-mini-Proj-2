{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:13:06.125605Z",
     "iopub.status.busy": "2025-05-13T12:13:06.124705Z",
     "iopub.status.idle": "2025-05-13T12:13:07.295647Z",
     "shell.execute_reply": "2025-05-13T12:13:07.295102Z",
     "shell.execute_reply.started": "2025-05-13T12:13:06.125563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:34:01.121342Z",
     "iopub.status.busy": "2025-05-13T12:34:01.121076Z",
     "iopub.status.idle": "2025-05-13T12:34:01.126178Z",
     "shell.execute_reply": "2025-05-13T12:34:01.125489Z",
     "shell.execute_reply.started": "2025-05-13T12:34:01.121321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using Batch Size: 64\n"
     ]
    }
   ],
   "source": [
    "DATASET_CSV = '/kaggle/input/image-input/output.csv'\n",
    "IMAGE_BASE_DIR = '/kaggle/working/images/small'\n",
    "MODEL_NAME = \"Salesforce/blip-vqa-base\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 64\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Using Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:18:29.169476Z",
     "iopub.status.busy": "2025-05-13T12:18:29.168664Z",
     "iopub.status.idle": "2025-05-13T12:18:38.143440Z",
     "shell.execute_reply": "2025-05-13T12:18:38.142802Z",
     "shell.execute_reply.started": "2025-05-13T12:18:29.169438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 33866 samples.\n",
      "Loading model: Salesforce/blip-vqa-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc137a864664bceae5941cae43be069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45d8632991544b49b29a07a1155279d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab48da9463c4cb2af870c74deb2dc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fc73cf541a43e08f7b11d2d46f7ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e393e562e3bc4e06aa557d5a301ac313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1712fd7e1c9345b6930ca1bb5d90a22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83006c9d94ce45d291ac6fd936bf2355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATASET_CSV)\n",
    "    # Optional: Sample the dataset for faster testing\n",
    "    # df = df.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Loaded {len(df)} samples.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {DATASET_CSV} not found. Make sure it's in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Load Model and Processor ---\n",
    "print(f\"Loading model: {MODEL_NAME}...\")\n",
    "processor = BlipProcessor.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = BlipForQuestionAnswering.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model.eval() # Set model to evaluation mode\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:19:46.460410Z",
     "iopub.status.busy": "2025-05-13T12:19:46.460189Z",
     "iopub.status.idle": "2025-05-13T12:19:46.466875Z",
     "shell.execute_reply": "2025-05-13T12:19:46.466030Z",
     "shell.execute_reply.started": "2025-05-13T12:19:46.460391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_vqa_prediction(image_path, question):\n",
    "    \"\"\"Gets a VQA prediction for a given image path and question.\"\"\"\n",
    "    try:\n",
    "        raw_image = Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: Image not found at {image_path}\")\n",
    "        return \"[Image Load Error]\"\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error loading image {image_path}: {e}\")\n",
    "        return \"[Image Load Error]\"\n",
    "\n",
    "    # Prepare inputs\n",
    "    inputs = processor(raw_image, question, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    # Generate answer\n",
    "    with torch.no_grad(): # Ensure no gradients are calculated during inference\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10) # Limit generated tokens for single-word answers\n",
    "\n",
    "    # Decode answer\n",
    "    answer = processor.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:20:15.181114Z",
     "iopub.status.busy": "2025-05-13T12:20:15.180789Z",
     "iopub.status.idle": "2025-05-13T12:20:15.203791Z",
     "shell.execute_reply": "2025-05-13T12:20:15.203062Z",
     "shell.execute_reply.started": "2025-05-13T12:20:15.181093Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>718mYsQTQbL</td>\n",
       "      <td>What are the items in the image?</td>\n",
       "      <td>Bibs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718mYsQTQbL</td>\n",
       "      <td>What color is the solid bib?</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>718mYsQTQbL</td>\n",
       "      <td>How many bibs are shown?</td>\n",
       "      <td>Six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718mYsQTQbL</td>\n",
       "      <td>What material are the bibs?</td>\n",
       "      <td>Cotton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>718mYsQTQbL</td>\n",
       "      <td>Does one bib have a striped pattern?</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                              question  answer\n",
       "0  718mYsQTQbL      What are the items in the image?    Bibs\n",
       "1  718mYsQTQbL          What color is the solid bib?  Yellow\n",
       "2  718mYsQTQbL              How many bibs are shown?     Six\n",
       "3  718mYsQTQbL           What material are the bibs?  Cotton\n",
       "4  718mYsQTQbL  Does one bib have a striped pattern?     Yes"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:30:28.872165Z",
     "iopub.status.busy": "2025-05-13T12:30:28.871255Z",
     "iopub.status.idle": "2025-05-13T12:30:29.149751Z",
     "shell.execute_reply": "2025-05-13T12:30:29.148598Z",
     "shell.execute_reply.started": "2025-05-13T12:30:28.872133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !gunzip /kaggle/working/images/metadata/images.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:31:02.796943Z",
     "iopub.status.busy": "2025-05-13T12:31:02.796256Z",
     "iopub.status.idle": "2025-05-13T12:31:03.250154Z",
     "shell.execute_reply": "2025-05-13T12:31:03.249508Z",
     "shell.execute_reply.started": "2025-05-13T12:31:02.796915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/working/listings/metadata\"\n",
    "\n",
    "df1 = pd.read_csv(r'/kaggle/working/images/metadata/images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:33:37.096667Z",
     "iopub.status.busy": "2025-05-13T12:33:37.096210Z",
     "iopub.status.idle": "2025-05-13T12:33:37.130014Z",
     "shell.execute_reply": "2025-05-13T12:33:37.129111Z",
     "shell.execute_reply.started": "2025-05-13T12:33:37.096646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4c/4c533ad7.jpg What are the items in the image? bibs\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    imageId = row['id']\n",
    "    question = row['question']\n",
    "    pt= df1[df1['image_id']==imageId]\n",
    "    pt= pt['path'].values[0]\n",
    "        \n",
    "    true_answer = str(row['answer']).lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T12:37:59.536816Z",
     "iopub.status.busy": "2025-05-13T12:37:59.536231Z",
     "iopub.status.idle": "2025-05-13T13:22:57.278792Z",
     "shell.execute_reply": "2025-05-13T13:22:57.277874Z",
     "shell.execute_reply.started": "2025-05-13T12:37:59.536792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batched inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c90b1dd077a4548b70873c692c6600b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Batches:   0%|          | 0/530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Running batched inference...\")\n",
    "predictions = []\n",
    "ground_truths_normalized = [] # Store normalized ground truths for metrics\n",
    "original_indices = []\n",
    "num_batches = math.ceil(len(df) / BATCH_SIZE)\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculations for inference\n",
    "    for i in tqdm(range(0, len(df), BATCH_SIZE), total=num_batches, desc=\"Evaluating Batches\"):\n",
    "        batch_df = df[i:i+BATCH_SIZE]\n",
    "\n",
    "        batch_images_pil = []\n",
    "        batch_questions = []\n",
    "        batch_ground_truths = []\n",
    "        batch_valid_indices = [] # Store original indices of valid items in this batch\n",
    "\n",
    "        # 1. Load images and collect data for the current batch\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            imageId = row['id']\n",
    "            question = row['question']\n",
    "            pt= df1[df1['image_id']==imageId]\n",
    "            pt= pt['path'].values[0]\n",
    "            true_answer = str(row['answer']).lower().strip()\n",
    "            img_path = os.path.join(IMAGE_BASE_DIR, pt)\n",
    "\n",
    "            try:\n",
    "                raw_image = Image.open(img_path).convert('RGB')\n",
    "                batch_images_pil.append(raw_image)\n",
    "                batch_questions.append(question)\n",
    "                batch_ground_truths.append(true_answer)\n",
    "                batch_valid_indices.append(idx) # Add original index if image loaded\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: Image not found at {img_path}. Skipping row {idx}.\")\n",
    "                # Optionally store placeholders for missing images if needed later\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error loading image {img_path} for row {idx}: {e}. Skipping.\")\n",
    "                # Optionally store placeholders\n",
    "\n",
    "        # 2. Process the batch if any valid images were loaded\n",
    "        if not batch_images_pil:\n",
    "            print(f\"Warning: No valid images loaded for batch starting at index {i}. Skipping batch.\")\n",
    "            continue # Skip to the next batch\n",
    "\n",
    "        # Use the processor for the entire batch\n",
    "        inputs = processor(images=batch_images_pil, text=batch_questions, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "\n",
    "        # 3. Generate answers for the batch\n",
    "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
    "\n",
    "        # 4. Decode and store results for the batch\n",
    "        batch_preds_decoded = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "        for pred_idx, original_df_idx in enumerate(batch_valid_indices):\n",
    "            # Normalize prediction\n",
    "            predicted_answer = batch_preds_decoded[pred_idx].strip().lower()\n",
    "            predicted_answer = re.sub(r'[^\\w\\s]', '', predicted_answer) # Basic cleanup\n",
    "\n",
    "            # Normalize corresponding ground truth\n",
    "            true_answer_normalized = batch_ground_truths[pred_idx] # Already lowercased/stripped\n",
    "            true_answer_normalized = re.sub(r'[^\\w\\s]', '', true_answer_normalized) # Basic cleanup\n",
    "\n",
    "            predictions.append(predicted_answer)\n",
    "            ground_truths_normalized.append(true_answer_normalized)\n",
    "            original_indices.append(original_df_idx) # Store the original index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# # Delete unused variables\n",
    "# del model, inputs, outputs  # or any other variables you created\n",
    "# gc.collect()                # Run garbage collection\n",
    "# torch.cuda.empty_cache()    # Release cached memory from PyTorch\n",
    "# torch.cuda.ipc_collect()    # Additional cleanup for inter-process communication (optional)\n",
    "# !nvidia-smi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T13:36:18.374403Z",
     "iopub.status.busy": "2025-05-13T13:36:18.373832Z",
     "iopub.status.idle": "2025-05-13T13:36:18.535861Z",
     "shell.execute_reply": "2025-05-13T13:36:18.535002Z",
     "shell.execute_reply.started": "2025-05-13T13:36:18.374375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to vqa_results_baseline_batched.csv\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'original_index': original_indices,\n",
    "    'predicted_answer': predictions,\n",
    "    'ground_truth_normalized': ground_truths_normalized\n",
    "})\n",
    "# import pandas as pd\n",
    "# results_df = pd.read_csv(\"./rs.csv\")\n",
    "# Merge results back with original dataframe (optional, but useful)\n",
    "# Ensure the original df has a unique index if it was reset during sampling\n",
    "df_with_results = df.merge(results_df, left_index=True, right_on='original_index', how='right') # 'right' join keeps only processed rows\n",
    "\n",
    "# Save results\n",
    "results_filename = 'vqa_results_baseline_batched.csv'\n",
    "df_with_results.to_csv(results_filename, index=False)\n",
    "print(f\"Results saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"./rs.csv\")\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv(\"../VR-mini-Proj-2/BLIP_vqa_results_baseline_batched.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T13:37:25.791255Z",
     "iopub.status.busy": "2025-05-13T13:37:25.790541Z",
     "iopub.status.idle": "2025-05-13T13:37:25.802207Z",
     "shell.execute_reply": "2025-05-13T13:37:25.801650Z",
     "shell.execute_reply.started": "2025-05-13T13:37:25.791230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\varni\\miniconda3\\envs\\tdr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import bert_score\n",
    "\n",
    "valid_predictions = results_df['predicted_answer'].to_list()\n",
    "valid_ground_truths = results_df['ground_truth_normalized'].to_list()\n",
    "\n",
    "if not valid_predictions:\n",
    "    print(\"Error: No valid predictions available to calculate metrics.\")\n",
    "    exit()\n",
    "\n",
    "# 1. Accuracy (Exact Match)\n",
    "correct_predictions = sum(p == gt for p, gt in zip(valid_predictions, valid_ground_truths))\n",
    "total_valid = len(valid_predictions)\n",
    "accuracy = correct_predictions / total_valid if total_valid > 0 else 0\n",
    "\n",
    "\n",
    "print(f\"Accuracy (Exact Match): {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T13:38:02.396149Z",
     "iopub.status.busy": "2025-05-13T13:38:02.395437Z",
     "iopub.status.idle": "2025-05-13T13:38:02.399811Z",
     "shell.execute_reply": "2025-05-13T13:38:02.399258Z",
     "shell.execute_reply.started": "2025-05-13T13:38:02.396128Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Macro, based on Exact Match): 0.4216\n"
     ]
    }
   ],
   "source": [
    "f1_macro_simple = accuracy # As explained before, for binary match/no-match\n",
    "print(f\"F1 Score (Macro, based on Exact Match): {f1_macro_simple:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "results = bertscore.compute(references=valid_ground_truths, predictions=valid_predictions,lang=\"en\",model_type=\"distilbert-base-uncased\",rescale_with_baseline=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.mean(results['precision']))\n",
    "print(np.mean(results['recall']))\n",
    "print(np.mean(results['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T13:56:45.771519Z",
     "iopub.status.busy": "2025-05-13T13:56:45.770702Z",
     "iopub.status.idle": "2025-05-13T13:56:48.745503Z",
     "shell.execute_reply": "2025-05-13T13:56:48.744830Z",
     "shell.execute_reply.started": "2025-05-13T13:56:45.771485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: tensor([1., 1., 0.,  ..., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "all_sentences = valid_predictions + valid_ground_truths\n",
    "vectorizer.fit(all_sentences)\n",
    "\n",
    "vec1 = vectorizer.transform(valid_predictions).toarray()\n",
    "vec2 = vectorizer.transform(valid_ground_truths).toarray()\n",
    "\n",
    "pred_vec = torch.tensor(vec1, dtype=torch.float32)\n",
    "gt_vec = torch.tensor(vec2, dtype=torch.float32)\n",
    "\n",
    "\n",
    "cos_sim = F.cosine_similarity(pred_vec, gt_vec, dim=1)\n",
    "print(\"Cosine similarity:\", cos_sim)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7406801,
     "sourceId": 11795298,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
